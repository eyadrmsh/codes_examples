{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SBERT"
      ],
      "metadata": {
        "id": "2jHVa2yfIVC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as english_stop_words\n",
        "import numpy as np\n",
        "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner', \"attribute_ruler\"])\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "sTc2PZ8HIW6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "kEndmdBbILL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rPDYMikXXqwJ"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train_responses.csv')\n",
        "dev = pd.read_csv('dev_responses.csv')\n",
        "\n",
        "smoothingfunction = SmoothingFunction()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqDn7zGYX3K_"
      },
      "outputs": [],
      "source": [
        "class sbert():\n",
        "\n",
        "  def __init__(self):\n",
        "      self.train = pd.read_csv('train_responses.csv')\n",
        "      self.dev = pd.read_csv('dev_responses.csv')\n",
        "\n",
        "  def clean_and_join(self, doc):\n",
        "    clean_tokens = [token.text.lower() for token in doc if not token.is_punct]\n",
        "    clean_sentence = ' '.join(clean_tokens)\n",
        "    return clean_sentence\n",
        "\n",
        "  def lemma(self, data):\n",
        "    user_propmts = list(data['user_prompt'])\n",
        "    lemmatized_propmts = list(nlp.pipe(user_propmts))\n",
        "    lemmatized_propmts = [self.clean_and_join(prompt) for prompt in lemmatized_propmts]\n",
        "    return lemmatized_propmts\n",
        "\n",
        "  def for_embed_delete_it_later(self):\n",
        "    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
        "    train_vectors = model.encode(self.lemma(self.train))\n",
        "    dev_vectors = model.encode(self.lemma(self.dev))\n",
        "    return train_vectors, dev_vectors\n",
        "\n",
        "  def best_answer(self):\n",
        "    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
        "    train_vectors = model.encode(self.lemma(self.train))\n",
        "    dev_vectors = model.encode(self.lemma(self.dev))\n",
        "    modified_dev = self.dev.copy()\n",
        "    for i in range(len(dev)):\n",
        "        given_prompt_tfidf = dev_vectors[i]\n",
        "        given_prompt_tfidf = np.array(given_prompt_tfidf).reshape(1, -1)\n",
        "        train_vectors = np.array(train_vectors).reshape(len(train_vectors), -1)\n",
        "        cosine_similarities = cosine_similarity(given_prompt_tfidf, train_vectors)\n",
        "        most_similar_prompt_index = cosine_similarities.argmax()\n",
        "        most_similar_prompt = train.loc[most_similar_prompt_index, 'user_prompt']\n",
        "        most_similar_answer = train.loc[most_similar_prompt_index, 'model_response']\n",
        "        modified_dev.loc[i,'retrieved_response'] = most_similar_answer\n",
        "    return modified_dev\n",
        "\n",
        "  def score(self):\n",
        "    modified_dev = self.best_answer()\n",
        "    modified_dev['model_response'] = modified_dev['model_response'].astype(str)\n",
        "    modified_dev['retrieved_response'] = modified_dev['retrieved_response'].astype(str)\n",
        "    modified_dev['bleu_score'] = modified_dev.apply(lambda x: sentence_bleu([x['model_response'].split()], x['retrieved_response'].split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothingfunction.method3), axis=1)\n",
        "    return np.mean(modified_dev['bleu_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqisoCA7YWMU"
      },
      "outputs": [],
      "source": [
        "MODEL = sbert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGPdWJ1gYc36",
        "outputId": "0f778a62-704f-4a52-8290-3878a576a10d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.09913395882522728"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL.score()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discrete Text Representation"
      ],
      "metadata": {
        "id": "EiFPxHVwIZc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Doc2VecEstimator():\n",
        "\n",
        "    def __init__(self,vector_size=300, window=5, min_count=5, epochs=500, dbow_words = 0, dm = 1 , hs=0, negative = 10):\n",
        "      self.vector_size = vector_size\n",
        "      self.window = window\n",
        "      self.min_count = min_count\n",
        "      self.epochs = epochs\n",
        "      self.dbow_words = dbow_words\n",
        "      self.dm = dm\n",
        "      self.hs = hs\n",
        "      self.negative = negative\n",
        "      self.model = None\n",
        "      self.train = pd.read_csv('train_responses.csv')\n",
        "      self.dev = pd.read_csv('dev_responses.csv')\n",
        "\n",
        "    def clean_and_join(self, doc):\n",
        "      clean_tokens = [token.lemma_.lower() for token in doc if not token.is_punct]\n",
        "      clean_sentence = ' '.join(clean_tokens)\n",
        "      return clean_sentence\n",
        "\n",
        "    def tagged(self, data):\n",
        "      user_propmts = list(data['user_prompt'])\n",
        "      lemmatized_propmts = list(nlp.pipe(user_propmts))\n",
        "      lemmatized_propmts = [self.clean_and_join(prompt) for prompt in lemmatized_propmts]\n",
        "      tagged_documents = [TaggedDocument(words=doc.split(), tags=[str(idx)]) for idx, doc in enumerate(lemmatized_propmts)]\n",
        "      return tagged_documents\n",
        "\n",
        "    def fit(self, train, dev):\n",
        "      self.model = Doc2Vec(\n",
        "            vector_size=self.vector_size,\n",
        "            window=self.window,\n",
        "            min_count=self.min_count,\n",
        "            epochs=self.epochs,\n",
        "            dbow_words=self.dbow_words,\n",
        "            dm=self.dm,\n",
        "            hs=self.hs,\n",
        "            negative=self.negative)\n",
        "      tagged_documents = self.tagged(train)\n",
        "      self.model.build_vocab(tagged_documents)\n",
        "      total_examples = len(tagged_documents)\n",
        "      self.model.train(tagged_documents, total_examples=total_examples,  epochs=self.epochs)\n",
        "      train_vectors = [self.model.dv[x] for x in range(len(self.tagged(train)))]\n",
        "      dev_vectors = [self.model.infer_vector(doc.words) for doc in self.tagged(dev)]\n",
        "\n",
        "      print(\"Model Parameters:\")\n",
        "      print(f\"Vector Size: {self.model.vector_size}\")\n",
        "      print(f\"Window: {self.model.window}\")\n",
        "      print(f\"HS: {self.model.hs}\")\n",
        "      print(f\"Sample: {self.model.sample}\")\n",
        "      print(f\"Negative: {self.model.negative}\")\n",
        "      print(f\"Min Count: {self.model.min_count}\")\n",
        "      print(f\"Workers: {self.model.workers}\")\n",
        "      print(f\"Epochs: {self.model.epochs}\")\n",
        "      print(f\"DM: {self.model.dm}\")\n",
        "      print(f\"DBOW Words: {self.model.dbow_words}\")\n",
        "\n",
        "      return train_vectors, dev_vectors\n",
        "\n",
        "    def best_answer(self):\n",
        "      train_vectors, dev_vectors = self.fit(train, dev)\n",
        "      modified_dev = dev.copy()\n",
        "      for i in range(len(dev)):\n",
        "        given_prompt_tfidf = dev_vectors[i]\n",
        "        given_prompt_tfidf = np.array(given_prompt_tfidf).reshape(1, -1)\n",
        "        train_vectors = np.array(train_vectors).reshape(len(train_vectors), -1)\n",
        "        cosine_similarities = cosine_similarity(given_prompt_tfidf, train_vectors)\n",
        "        most_similar_prompt_index = cosine_similarities.argmax()\n",
        "        most_similar_prompt = train.loc[most_similar_prompt_index, 'user_prompt']\n",
        "        most_similar_answer = train.loc[most_similar_prompt_index, 'model_response']\n",
        "        modified_dev.loc[i,'retrieved_response'] = most_similar_answer\n",
        "      return modified_dev\n",
        "\n",
        "    def score(self):\n",
        "      modified_dev = self.best_answer()\n",
        "      modified_dev['model_response'] = modified_dev['model_response'].astype(str)\n",
        "      modified_dev['retrieved_response'] = modified_dev['retrieved_response'].astype(str)\n",
        "      modified_dev['bleu_score'] = modified_dev.apply(lambda x: sentence_bleu([x['model_response'].split()], x['retrieved_response'].split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothingfunction.method3), axis=1)\n",
        "      print(np.mean(modified_dev['bleu_score']))\n",
        "      return np.mean(modified_dev['bleu_score'])"
      ],
      "metadata": {
        "id": "BYBjGcb5Igkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = Doc2VecEstimator(vector_size=300, window=2, min_count=3, epochs=500, dbow_words = 0, dm = 0 , hs=0, negative = 10)\n",
        "estimator.score()"
      ],
      "metadata": {
        "id": "Za0IxaLVIrX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Static text representation"
      ],
      "metadata": {
        "id": "Lpd0VyjfI3Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "IthKIZREI6Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tfidf_vect():\n",
        "\n",
        "  def __init__(self, train_responses, dev_responses):\n",
        "    self.train = train_responses\n",
        "    self.dev = dev_responses\n",
        "\n",
        "  def clean_and_join(self, doc):\n",
        "    clean_tokens = [token.text.lower() for token in doc if not token.is_punct]\n",
        "    clean_sentence = ' '.join(clean_tokens)\n",
        "    return clean_sentence\n",
        "\n",
        "  def lemmatized_prompts(self, data):\n",
        "    user_propmts = list(data['user_prompt'])\n",
        "    lemmatized_propmts = list(nlp.pipe(user_propmts))\n",
        "    lemmatized_propmts = [clean_and_join(prompt) for prompt in lemmatized_propmts]\n",
        "    return lemmatized_propmts\n",
        "\n",
        "  def tfidf(self, train, dev):\n",
        "    tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
        "                                   sublinear_tf=True,\n",
        "                                   ngram_range=(1, 2), norm = 'l1', smooth_idf = True)\n",
        "\n",
        "    train_tfidf = tfidf_vectorizer.fit_transform(self.lemmatized_prompts(train))\n",
        "    dev_tfidf = tfidf_vectorizer.transform(self.lemmatized_prompts( dev))\n",
        "    return train_tfidf, dev_tfidf\n",
        "\n",
        "  def blue_score(self, train, dev):\n",
        "    train_tfidf, dev_tfidf = self.tfidf(train, dev)\n",
        "    for i in range(len(dev)):\n",
        "      given_prompt_tfidf = dev_tfidf[i]\n",
        "      cosine_similarities = cosine_similarity(given_prompt_tfidf, train_tfidf)\n",
        "      most_similar_prompt_index = cosine_similarities.argmax()\n",
        "      most_similar_answer = train.loc[most_similar_prompt_index, 'model_response']\n",
        "      dev.loc[i,'retrieved_response'] = most_similar_answer\n",
        "\n",
        "    dev['model_response'] = dev['model_response'].astype(str)\n",
        "    dev['retrieved_response'] = dev['retrieved_response'].astype(str)\n",
        "    dev['bleu_score'] = dev.apply(lambda x: sentence_bleu([x['model_response'].split()], x['retrieved_response'].split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothingfunction.method3), axis=1)\n",
        "\n",
        "    print(f'Using cosine similarities blue score is {dev[\"bleu_score\"].mean()}')\n",
        "\n",
        "\n",
        "    for i in range(len(dev)):\n",
        "        given_prompt_tfidf = dev_tfidf[i]\n",
        "        cosine_similarities = euclidean_distances(given_prompt_tfidf, train_tfidf)\n",
        "        most_similar_prompt_index = cosine_similarities.argmin()\n",
        "        most_similar_answer = train.loc[most_similar_prompt_index, 'model_response']\n",
        "        dev.loc[i,'retrieved_response'] = most_similar_answer\n",
        "\n",
        "\n",
        "    dev['model_response'] = dev['model_response'].astype(str)\n",
        "    dev['retrieved_response'] = dev['retrieved_response'].astype(str)\n",
        "    dev['bleu_score'] = dev.apply(lambda x: sentence_bleu([x['model_response'].split()], x['retrieved_response'].split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothingfunction.method3), axis=1)\n",
        "\n",
        "    print(f'Using eucledian distance blue score is {dev[\"bleu_score\"].mean()}')"
      ],
      "metadata": {
        "id": "ujMwngvWI7ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = tfidf_vect(train, dev)\n",
        "MODEL.blue_score(train,dev)"
      ],
      "metadata": {
        "id": "8x3tGJgsJChI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
